// Databricks notebook source
// MAGIC %python
// MAGIC configs = {
// MAGIC 			"fs.azure.account.auth.type": "OAuth",
// MAGIC 			"fs.azure.account.oauth.provider.type": "org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider",
// MAGIC 			"fs.azure.account.oauth2.client.id": "942dd7f7-f97a-4312-9b1e-bd0d6c7dc9df",
// MAGIC 			"fs.azure.account.oauth2.client.secret": "+[omfx@:Z7nBytgX5btBG4jYsFBWgS58",
// MAGIC 			"fs.azure.account.oauth2.client.endpoint": "https://login.microsoftonline.com/72f988bf-86f1-41af-91ab-2d7cd011db47/oauth2/token",
// MAGIC 			"fs.azure.createRemoteFileSystemDuringInitialization": "true"
// MAGIC 		}

// COMMAND ----------

// MAGIC %python
// MAGIC 
// MAGIC dbutils.fs.mount(
// MAGIC source = "abfss://data@adbstoregen2.dfs.core.windows.net/",
// MAGIC mount_point = "/mnt/salesdata1",
// MAGIC extra_configs = configs)

// COMMAND ----------

// MAGIC %fs
// MAGIC 
// MAGIC ls /mnt/salesdata1

// COMMAND ----------

val fileName = "/mnt/salesdata1/ratings-c.csv"
val data = sc.textFile(fileName).mapPartitionsWithIndex(
  (index, iterator) => {
    if(index == 0) {
      iterator.drop(1)
    }
    
    iterator
  }).map(line => {
    val splitted = line.split(",")
  
    (splitted(2).toFloat, 1)
  })

val pdata = data.reduceByKey((value1, value2) => value1 + value2).sortBy(_._2).collect

pdata.reverse.foreach(println)

// COMMAND ----------

